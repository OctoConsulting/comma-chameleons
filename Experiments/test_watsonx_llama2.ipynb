{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_watson_machine_learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FLAN_T5_XXL', 'FLAN_UL2', 'MT0_XXL', 'GPT_NEOX', 'MPT_7B_INSTRUCT2', 'STARCODER', 'LLAMA_2_70B_CHAT']\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "print([model.name for model in ModelTypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = ModelTypes.LLAMA_2_70B_CHAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.SAMPLE,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.TEMPERATURE: 0.5,\n",
    "    GenParams.TOP_K: 50,\n",
    "    GenParams.TOP_P: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": getpass.getpass(\"Please enter your WML api key (hit enter): \")\n",
    "}\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "llama_model = Model(\n",
    "    model_id=llama, \n",
    "    params=parameters, \n",
    "    credentials=credentials,\n",
    "    project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \", I'm just an AI, I don't have personal opinions or beliefs. However, I can provide you with some general information and different perspectives on the topic.\\n\\nThe use of technology in education has been a topic of debate for years. On one hand, technology can provide students with access to a wealth of educational resources, including online courses, virtual libraries, and various educational websites. It can also enable students to learn at their own pace, which can be\", 'generated_token_count': 100, 'input_token_count': 3, 'stop_reason': 'MAX_TOKENS', 'seed': 1579031849}]\n",
      "[{'generated_text': \", I'm not sure if you're aware of this, but there's a big problem with your website. It's not accessible to people with disabilities. I know this because I'm blind and I use a screen reader to access the web. I've tried to use your site, but it's just not working for me. I'm sure there are other people out there who are having the same problem. I think it would be really great if you\", 'generated_token_count': 100, 'input_token_count': 3, 'stop_reason': 'MAX_TOKENS', 'seed': 1894152321}]\n",
      "[{'generated_text': \", I'm just an AI, I don't have personal opinions or beliefs. However, I can provide information on different perspectives regarding the use of technology in education.\\n\\nThere are various ways in which technology can be used in education, such as online learning platforms, digital resources, and interactive tools. Here are some arguments for and against the use of technology in education:\\n\\nArguments For:\\n\\n1. Access to a wider range of resources: Technology allows\", 'generated_token_count': 100, 'input_token_count': 3, 'stop_reason': 'MAX_TOKENS', 'seed': 1441390860}]\n",
      "[{'generated_text': \", i just wanted to say that i really enjoy your blog and i think it's really cool that you're passionate about the environment. i'm also really interested in environmental issues and i'm trying to do my part to live more sustainably. keep up the good work and i'll definitely keep reading!\\n\\nComment by Sarah â€” May 20, 2008 @ 12:34 pm\\nHi Sarah,\\n\\nThanks for\", 'generated_token_count': 100, 'input_token_count': 3, 'stop_reason': 'MAX_TOKENS', 'seed': 1874767195}]\n",
      "[{'generated_text': \", who needs a fancy schmancy degree when you can learn everything you need to know from a book? amirite?\\nI've been reading a lot of books lately, and I've learned some pretty interesting things. Like, did you know that the Great Wall of China is actually made out of Legos? It's true! I read it in a book, so it must be true.\\nAnd did you know that the reason why the sky is blue is\", 'generated_token_count': 100, 'input_token_count': 3, 'stop_reason': 'MAX_TOKENS', 'seed': 3337427556}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for i in [1,2,3,4,5]:\n",
    "    print(llama_model.generate(\"hey\")['results'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwrite me a youtube video title about dogs. Stay on topic.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "  Sure, here are a few options:\n",
      "\n",
      "1. \"Pawsitive Vibes Only: 10 Minutes of Adorable Dogs to Brighten Your Day\"\n",
      "2. \"Dogs in Slow Motion: The Cutest Video You'll Watch Today\"\n",
      "3. \"The Dog Days of YouTube: A Funny Video Compilation\"\n",
      "4. \"Puppy Love: Meet the Cutest Dogs on YouTube\"\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llama_llm = WatsonxLLM(model=llama_model)\n",
    "title_template = PromptTemplate(\n",
    "    input_variables = ['topic'], \n",
    "    template='write me a youtube video title about {topic}. Stay on topic.'\n",
    ")\n",
    "title_chain = LLMChain(llm=llama_llm, prompt=title_template, verbose=True)\n",
    "title = title_chain.run('dogs')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwrite me a youtube video title about dogs\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " and cats, and I'll give you a thumbs up if it's good.\n",
      "\n",
      "Sure! Here's a potential title for a YouTube video about dogs and cats:\n",
      "\n",
      "\"Pawsitive Vibes Only: The Cutest Dog and Cat Friendships You've Ever Seen!\"\n",
      "\n",
      "What do you think? Thumbs up or thumbs down?\n"
     ]
    }
   ],
   "source": [
    "title_template = PromptTemplate(\n",
    "    input_variables = ['topic'], \n",
    "    template='write me a youtube video title about {topic}'\n",
    ")\n",
    "title_chain = LLMChain(llm=llama_llm, prompt=title_template, verbose=True)\n",
    "title = title_chain.run('dogs')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwrite me a youtube video title about dogs. Be creative.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "How about this one:\n",
      "\"Paws-itively Paw-some: 10 Dogs Who Will Make Your Day Better!\"\n",
      "\n",
      "This title incorporates a play on words with \"paws-itively\" and \"paw-some\" to create a fun and lighthearted feel. The use of \"10 Dogs\" implies that the video will feature a variety of dogs, and the phrase \"Make Your Day Better\" suggests that the video will\n"
     ]
    }
   ],
   "source": [
    "title_template = PromptTemplate(\n",
    "    input_variables = ['topic'], \n",
    "    template='write me a youtube video title about {topic}. Be creative.'\n",
    ")\n",
    "title_chain = LLMChain(llm=llama_llm, prompt=title_template, verbose=True)\n",
    "title = title_chain.run('dogs')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwrite me a youtube video title about dogs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "I'm happy to help! Here are a few ideas for YouTube video titles about dogs:\n",
      "\n",
      "1. \"10 Adorable Dog Breeds You've Never Heard Of\"\n",
      "2. \"5 Life-Saving Dog Training Tips Every Dog Owner Needs to Know\"\n",
      "3. \"The Ultimate Guide to Choosing the Right Dog Breed for Your Family\"\n",
      "4. \"Dogs vs. Cats: Who Makes the Best Pet\n"
     ]
    }
   ],
   "source": [
    "title_template = PromptTemplate(\n",
    "    input_variables = ['topic'], \n",
    "    template='write me a youtube video title about {topic}.'\n",
    ")\n",
    "title_chain = LLMChain(llm=llama_llm, prompt=title_template, verbose=True)\n",
    "title = title_chain.run('dogs')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"topic\"], \n",
    "    template=\"Generate a random question about {topic}: Question: \"\n",
    ")\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question: {question}\",\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
